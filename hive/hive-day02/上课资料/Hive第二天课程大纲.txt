马 骉骉biao老师 Hive数据分析 第二天

第一部分：Hive第一天：Hive基础认识

1、为什么要有hive要使用hive？
	数据量越来越大
	mapreduce来执行海量数据的分析，但是
		执行效率低
		编码复杂
		学习难度高
	目的：
		想要处理海量的结构化数据的统计分析
		采取类似于MySQL的表的形式的操作方式：SQL
		但是数据量很大，所以就么法直接使用MySQL
		研发一个类似于MySQL的组件
	
	针对海量数据的统计分析
	1、给用户的使用：SQL方式
	2、底层运行机制：SQL翻译成MapREduce程序来执行的

2、Hive的概念和数据仓库的概念

	hive是一个数据仓库工具
	把结构化的数据，看做是类似于mysql中的表结构
	提供了一个中SQL的操作方式
	底层的真实数据存储的HDFS上，也要依托于一个数据库来管理元数据（mysql等RDBMS）
	原理就是hive把sql翻译成mapreduce程序提交给hadoop集群来运行
	作用，就是使不熟悉大数据技术组件的技术人员，可以快速进行海量数据的统计分析
	SQL的学习难度要远远低于mapreduce，而且使用体验更优

	hive只是解决了MapReduce的编码复杂的问题，但是并没有解决执行效率低的问题

	数据仓库：
		侧重于查询，OLAP系统，事务特性支持不完善。
	概念：面向主题的，相对稳定的，反映历史数据变化规律的一个数据集合
	类似于数据库，但是更多的是侧重于查询分析，而不是事务操作（增删改）
	
3、mysql和hive的区别（异同）

4、hive的内部机制
	
	用户接口
		webui，cli，jdbc
	thrift server 
		跨语言服务
	内部组成
		驱动器 driver
		编译器 compiler
		优化器 optimizer
		执行器 executor
	元数据库
		mysql，derby，oracle RDBMS
	
	hive的真正的能力，把结构化的数据看作是一张类似于mysql表的二维结构。
	提供sql的操作方式
	这张表有表的定义数据，也有表的真实数据
	1、定义数据：
		元数据：表的名字，表中的字段的名字和类型
	2、真实数据
		表中的数据

	元数据：描述真实数据的数据

5、hive的数据存储
	
	数据库
	数据表
		内部表
		外部表
		分区表
		分桶表
	视图
	数据文件

6、hive的环境搭建
	
	只需要做一次！ 只要有这个环境

7、hive的一个基本使用




第二部分：Hive第二天：HQL核心语法

MySQL：
	了解一下关于关系型数据的一些基础理论
	数据存储在mysql中，如果想操作这个数据，咱么能使用的是：SQL语言

	分为以下三大类型：
	1、DDL
	2、DML
	3、DQL

主要内容：
1、DDL	数据定义语言 主要是创建，删除，修改库和表定义等
2、DML	数据操纵语言 主要是导入，到处，插入，清空表的数据等， 也有导出操作
	hive没有针对单条记录的删除和修改（delete update 不支持！）
3、DQL  数据查询语言 查询 select

核心知识点：
1、创建库和表
2、导入数据
3、查询SQL

基础使用过程中：
1、查询有那些库
2、切换到要使用的库
3、查看该库中有那些表
4、如果没有表，则创建表
5、往里面导入数据
	mysql：insert插入数据， 针对一条一条数据的插入
	hive：load导入数据， 针对一批次数据的直接导入
6、写select查询



一个HDFS集群的存储能力到底如何?
1、集群：节点个数
2、每个节点的存储能力

节点个数 * 每个节点的存储能力  =  总存储能力

首先在
先从win7导入数据到linux系统
再从linux系统导入数据到HDFS里


表：
1、元数据
2、真实数据

在插入数据之前创建表，肯定是已经知道了要插入的数据是什么了。
所以才能创建表。

一般都是根据数据长什么样子，然后根据数据的样式来创建对应的表

分区的问题

不管是任何的表，都有自己的一个数据存储目录


如果是分区表，这个表的数据文件没有直接存储在表目录中
而是在表目录中，区分出来了多个不同的文件夹，每个文件夹就属于一个分区，在某个文件夹下的数据就属于这张表的这个分区

总表没有这个概念

一个分区表，就是一张表
这张表是由多个分区组成的而已

select ..... from table where age = 19
			where city = beijing 
			where date = 20191112

		
分桶表在做查询的时候和普通表是没有区别的

仅仅只是在当前这个分桶表做join查询的时候，自动提高执行效率

如果有一份数据经常用来做join查询，那就一定要给这张表建成一张分桶表

应用场景：
1、如果经常做条件筛选，则按照条件作为分区字段来创建分区表
2、如果一张表经常按照某个条件来做join查询，则按照这个条件字段作为分桶字段创建分桶表

select a.* , b.* from a join b on a.id = b.id;
一个条件：必须a表和b表是相同的分桶条件！
	1、分桶的字段必须一致
	2、a表和b表的分桶的个数，必须要成倍数

a:10
b: 5  20 30
11  27 33

分桶字段可以有多个
分区字段也可以有多个

多级分区

city=beijing&district=chaoyang

分桶的规则是可以指定的。
由于有两个原因的限制，基本上不需要去自定义：
1、由于分桶表的目的 用来提高join查询的效率
2、由于要自定义分区规则的话，就需要学习java，使用java来编写一个类：Partitioner



宏观上，其实意义一样的。：把一个大文件拆分成多个独立的小部分
		hive:
		1、文件夹：分区
		2、文件：分桶

分区还是分桶，总之，都是把数据分开

分开的规则，就由业务来决定

常见的有以下几种：
数据分区/分桶的规则：
1、hash散列
2、轮询分区
3、随机分区
4、范围分区
5、自定义分区

很正常。  按照天分区  正常的按天分区

where date = today  yesterday  tomorrow  20191112

没有缺点：相对普通表来说，要多做一些操作
剩下的都是好处!