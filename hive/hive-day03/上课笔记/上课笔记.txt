课前两个问题：
1、能听到么？
2、能看到么？
能听到，能看到 扣1
否则，扣2 

Hive数据仓库 第二天 内容回顾

hive数据仓库的核心知识：
1、DDL
2、DML
3、DQL

通俗讲：
1、创建表
2、导入数据
3、查询分析

hive数据仓库 第三天 内容预告

1、DML导入数据 
	创建表之后，怎么把数据弄到表里面去
2、DQL查询分析
	 select查询分析的语句
3、数据类型和函数
	创建表的时候：数据类型
	函数，具有特殊功能的字段处理的一些预定义逻辑   查询分析

hive全操作.txt



String  字符串 （abc，abc123, 黄渤，_012_abc， "123"）
int    数值类型（123， 345,  3， 8888 ）

int类型，可以看做是string类型的， 
但是
stirng类型，没法看做是int类型


关于插入数据的五种方式：
1、load方式导入数据
	本地
	HDFS
2、insert方式
	单条记录
	单重插入
	多重插入
3、CTAS
	create table ... as select ....
4、分区插入
	静态分区插入
	动态分区插入
5、分桶插入
	1、isnert ... select ..
	2、分桶查询（select分支就是分桶查询）


创建表
导入数据
查询分析

	基本的四种查询
	连接查询


hive的select和mysql的sql的区别！
1、select * from db.table1
2、select count(distinct uid) from db.table1
3、支持 select、union all、join（left、right、full join）、like、where、having、各种聚合函数、
	普通select, 合并， 连接
支持 json 解析
4、UDF（User Defined Function）/ UDAF/UDTF
	支持自定义函数：自定义函数式是使用java和python去定义。！ 
	函数中的两种：
	1、内置函数 271个！
	2、自定义函数
5、不支持 update 和 delete
6、hive 虽然支持 in/exists（老版本是不支持的），但是 hive 推荐使用 semi join 的方式来代替
实现，而且效率更高。
	select * from student where id in (95010, 95011)   hive-0.8x 以前不支持
	现在支持了，但是不推荐使用， 因为有更高效的操作
	semi join
7、支持 case … when …

hive侧重于查询的。

关于做join查询的时候：
1、支持等值连接，不支持非等值连接
	select a.* , b.* from a join b on a.id = b.id    √√√√√√
	select a.* , b.* from a join b on a.id > b.id    xxxxxx

2、支持多条件and操作，不支持or操作
	select a.* , b.* from a join b on a.id = b.id and a.name = b.name;    √√√√√√
	select a.* , b.* from a join b on a.id = b.id or  a.name = b.name;    √√√√√√

由于hive的SQL语句要翻译成MR程序，MR程序实现这两个SQL逻辑的操作很困难。
所以hive不支持这个语法！
	

select count(distinct id) as n1, count(*) as n2 from t1;
count(distinct id) as n1 到底是如何执行的呢？
	先按照group by id 来分组，然后每组进行count操作！！
	上一组根据ID分组，会分成多组
count(*) as n2
	这一组是所有记录都是一组，正常来理解是冲突的

select count(distinct department) as n1, count(*) as n2 from student;
 # 虽然能执行，但是结果呈现是不对的。！
select count(distinct department) as n1, count(distinct age) as n2 from student;	

select 
from 
join .. on ..
where ...
group by 
having 
order by  
limit 

都支持！而且关于limit这个操作，就算没有必要写，也最好加上！
select * from student order by id desc limit 10;


关于hive查询中，最关键的四个by：
1、order by 
	全局排序！
	如果这张表的数据量比较大，那么正常应该是启动很多个任务来执行
	但是由于是全局排序，基于业务的实现，必须要弄成是一个任务来执行
	一个任务执行很多数据的处理，执行效率不高。！
	慎用！
2、sort by 
	必须要使用多个任务来做
	sort by的目的，就是给每个任务中的处理的结果数据都按照对应的条件来进行排序
	执行多少个任务，每个任务都会按照来进行排序
	set mapreduce.job.reduces = 3;
	select * from student sort by age desc;
	结果：分成三段，每一段都是先找age降序排序！


我的数据量就是很大， 我就是想要实现全局排序，我就是想要很快出结果 怎么搞？
1、单独使用order by肯定可以，但是效率低，
2、使用sort by可以给每一部分数据排序，但是能否保证全局有序，得取决于分区的策略！
	使用什么分区策略，可以保证数据是全局有序的呢？
	范围分区！！！！！！
	默认的分区策略不是范围分区，而是hash散列！
3、cluster by 
	分桶 
	如果分桶字段和排序字段一样，就可以简写成为 cluster by 
	select * from student distribute by age sort by age desc;
	等同于：
	select * from student cluster by age;
4、distribute by
	分桶,只分桶，每个桶不排序
	如果要排序，搭配sort by使用

distribute by id sort by id  = cluster by id

group by  分组
select department, count(*) as total from student group by department;

case...when ... 把连续数据离散化！

90-100： A
80-90： B
60-80： C
0-60： D

case when 可以做数据分区

join查询！！

分类：
三类：
1、内连接 inner join 
根据连接条件返回在两张表中该字段值都存在的连接的记录
select a.* , b.* from a join b on a.id = b.id;
2       xuzheng 2       20
4       wangbaoqiang    4       50
7       fengjie 7       80
10      liudehua        10      22

2、外连接 outer join
	左外连接
	select a.* , b.* from a left outer join b on a.id = b.id;
	除了返回共同的记录之外，还返回存在于左表不存在于右表的记录
	右外连接
	全外连接
	select a.* , b.* from a full outer join b on a.id = b.id;
		共同的记录
		左表独有的记录
		右表独有的记录
	
3、半连接 semi join 
	依然也是一个连接，但是不一样的是：只返回两张表中的左表中的所有字段，不能返回右表中的字段，
	右表就是作为一个条件了。
	select a.id , a.name from a left semi join b on a.id = b.id;
	select a.id, a.name from a where a.id in (select id from b);

	当做是hive中堆 in/exists 两种语法的高效实现！！！

case  age  when > 80  then "A" when > 60 then "B" end as grade


tabla.txt
1,huangbo
2,xuzheng
4,wangbaoqiang
6,huangxiaoming
7,fengjie
10,liudehua

create database if not exists jointest;
use jointest;
drop table if exists a;
create table a(id int, name string) row format delimited fields terminated by ",";
load data local inpath "/home/hadoop/a.txt" into table a;
create database if not exists jointest;
use jointest;
drop table if exists b;
create table b(id int, age int) row format delimited fields terminated by ",";
load data local inpath "/home/hadoop/b.txt" into table b;


函数   数据类型


分桶表中的数据，就是通过分桶查询得来的。
先创建分桶表，
然后写分桶查询插入数据

15大类
1、字符串
2、日期时间
....

一个终极心法， 全学会！ 

三步走

周三记得：准时入场

作业和文档，还有操作 多写多练！ 

8点